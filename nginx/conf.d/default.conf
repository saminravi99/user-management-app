############################################################################
# NGINX ROUTING CONFIGURATION FOR USER MANAGEMENT APPLICATION
#
# WHY: This file exists to act as a traffic cop for your application
#      It decides where each incoming request should go
#
# WHAT: A reverse proxy configuration that routes requests to either:
#       - Frontend (Next.js React app) for web pages
#       - Backend (Node.js API) for data operations
#       Think of it as a smart switchboard operator
#
# HOW: Uses URL patterns to make routing decisions:
#      - Requests to /api/* go to backend
#      - Everything else goes to frontend
#      Also handles load balancing if you have multiple servers
#
# WHERE: This file is loaded by the main nginx.conf
#        It runs inside the Nginx Docker container
#
# WHICH: Routes configured here:
#        1. /api - Backend API endpoints
#        2. /_next/static - Next.js static files (JavaScript, CSS)
#        3. / - Frontend application (catch-all for all pages)
#        4. /health - Health check endpoint
############################################################################

############################################################################
# UPSTREAM BLOCKS - Define backend servers
# Think of these as phone directory entries for your services
############################################################################

upstream backend_api {
    # What is "upstream"?
    # It's a group of servers that can handle requests
    # Nginx can distribute load across multiple servers automatically
    
    least_conn;
    # Explanation: Load balancing algorithm
    # "least_conn" = send request to server with fewest active connections
    # Other options: round_robin (default), ip_hash (same user → same server)
    # Why least_conn: Ensures servers with lighter load get more requests
    
    server backend:5000 max_fails=3 fail_timeout=30s;
    # Explanation: The actual backend server location
    # "backend" is the Docker Compose service name (not localhost!)
    # "5000" is the port our Node.js API listens on
    # "max_fails=3" means: If 3 requests fail in a row, mark server as down
    # "fail_timeout=30s" means: Wait 30 seconds before trying failed server again
    #
    # If you want to run multiple backend instances (horizontal scaling):
    # Uncomment these lines and Nginx will distribute load automatically:
    # server backend2:5000 max_fails=3 fail_timeout=30s;
    # server backend3:5000 max_fails=3 fail_timeout=30s;
    
    keepalive 32;
    # Explanation: Keep 32 idle connections open to backend
    # Why: Reusing connections is faster than creating new ones each time
    # If traffic spike hits, these 32 connections are ready to go
}

upstream frontend_app {
    # Similar to backend_api above, but for our Next.js frontend server
    
    server frontend:3000 max_fails=3 fail_timeout=30s;
    # "frontend" is Docker Compose service name
    # "3000" is default Next.js port
    
    keepalive 32;
    # Keep connections to frontend alive for performance
}

############################################################################
# MAIN SERVER BLOCK - The actual web server configuration
############################################################################
server {
    # What is a "server block"?
    # It's like a virtual web server - one Nginx can host many server blocks
    # Each server block can handle different domains or ports
    
    ########################################################################
    # LISTENING CONFIGURATION - Which port to accept connections on
    ########################################################################
    listen 80;
    # Explanation: Listen for HTTP traffic on port 80 (standard web port)
    # When user types http://yoursite.com, their browser connects to port 80
    
    listen [::]:80;
    # Same as above but for IPv6 addresses
    # The [::] is IPv6 notation for "all IPv6 addresses"
    
    ########################################################################
    # SERVER NAME - Which domain names this server responds to
    ########################################################################
    server_name _;
    # Explanation: The underscore (_) is a catch-all wildcard
    # Matches ANY domain name that points to this server
    # 
    # For production, replace with your actual domain:
    # server_name example.com www.example.com;
    #
    # Why use _: During development, you might access via:
    # - http://localhost
    # - http://192.168.1.100 (local IP)
    # - http://your-azure-vm.com
    # The _ catches all of these
    
    ########################################################################
    # UPLOAD LIMITS
    ########################################################################
    client_max_body_size 20M;
    # Explanation: Maximum size of request body (file uploads)
    # 20M = 20 megabytes
    # Example use cases:
    # - User profile photo upload: 2-5 MB
    # - Document upload: 5-10 MB
    # - Resume/CV upload: 1-2 MB
    # If user tries to upload 25MB file, they'll get 413 error (too large)
    
    root /usr/share/nginx/html;
    # Explanation: Fallback directory for static files
    # We're not using this since we proxy everything
    # But good practice to define it for error pages
    
    charset utf-8;
    # Explanation: Tell browser to use UTF-8 encoding
    # Supports international characters, emojis, special symbols
    # Without this, some characters might display as ���

    ########################################################################
    # LOCATION BLOCK 1: BACKEND API
    # Pattern: /api/anything → goes to Node.js backend
    ########################################################################
    location /api {
        # How location matching works:
        # User requests: http://yoursite.com/api/users
        # Nginx sees "/api" and enters this block
        # Then forwards to backend server
        
        proxy_pass http://backend_api;
        # Explanation: Forward this request to the backend_api upstream
        # "backend_api" refers to the upstream block defined above
        # Nginx automatically does load balancing across servers in that upstream
        #
        # Example flow:
        # 1. User's browser: GET /api/users
        # 2. Nginx receives it
        # 3. Nginx forwards to: http://backend:5000/api/users
        # 4. Backend processes and responds
        # 5. Nginx sends response back to user
        
        ####################################################################
        # PROXY HEADERS - Preserve information about the original request
        ####################################################################
        proxy_set_header Host $host;
        # Explanation: Tell backend what domain user requested
        # Example: If user accessed "example.com", backend knows the domain
        # Why needed: Backend might need to generate correct URLs
        
        proxy_set_header X-Real-IP $remote_addr;
        # Explanation: Send user's actual IP address to backend
        # $remote_addr = the IP that connected to Nginx
        # Why needed: Backend logs, analytics, security (rate limiting by IP)
        
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        # Explanation: Chain of proxies request went through
        # Format: "client-ip, proxy1-ip, proxy2-ip"
        # Why needed: If you have multiple proxies, backend can see full path
        
        proxy_set_header X-Forwarded-Proto $scheme;
        # Explanation: Tell backend if request was HTTP or HTTPS
        # $scheme = "http" or "https"
        # Why needed: Backend might need to generate URLs with correct protocol
        
        ####################################################################
        # WEBSOCKET SUPPORT - For real-time features
        ####################################################################
        proxy_http_version 1.1;
        # Explanation: Use HTTP/1.1 protocol for proxying
        # Required for WebSockets (real-time connections)
        # HTTP/1.0 doesn't support persistent connections needed for WebSockets
        
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        # Explanation: These headers enable WebSocket connections
        # WebSocket starts as HTTP request, then "upgrades" to WebSocket
        # If you add real-time features later (live notifications, chat), this is ready
        
        ####################################################################
        # TIMEOUTS - How long to wait for backend
        ####################################################################
        proxy_connect_timeout 60s;
        # Explanation: Maximum time to establish connection to backend
        # If backend doesn't respond in 60 seconds, give up
        # Usually happens in <1 second, but allow buffer for slow starts
        
        proxy_send_timeout 60s;
        # Explanation: Maximum time to send request to backend
        # If sending takes >60 seconds, something is very wrong
        
        proxy_read_timeout 60s;
        # Explanation: Maximum time to wait for backend's response
        # If your API has slow operations (complex database queries, external API calls)
        # they must complete within 60 seconds or user gets timeout error
        # Adjust higher if you have legitimate slow operations
        
        ####################################################################
        # BUFFERING - How to handle response data
        ####################################################################
        proxy_buffering on;
        # Explanation: Buffer backend's response before sending to client
        # Why: If backend is fast but client is slow (poor connection),
        # buffering frees up backend faster - it doesn't wait for slow client
        
        proxy_buffer_size 4k;
        # Explanation: Size of buffer for response headers
        # 4KB is plenty for typical headers
        
        proxy_buffers 8 4k;
        # Explanation: 8 buffers, each 4KB = 32KB total buffer space
        # Used for buffering response body
        # Adjust if you have very large API responses
        
        proxy_busy_buffers_size 8k;
        # Explanation: How much data can be "busy" (being sent to client)
        # 8KB = 2 buffers worth
        
        ####################################################################
        # CACHING - API responses should NOT be cached
        ####################################################################
        add_header Cache-Control "no-cache, no-store, must-revalidate";
        # Explanation: Tell browser never to cache API responses
        # Why: API data changes frequently, cache would show stale data
        # "no-cache" = check with server before using cache
        # "no-store" = don't save to disk
        # "must-revalidate" = expired cache must be revalidated
        
        add_header Pragma "no-cache";
        # Old HTTP/1.0 way of saying "no-cache"
        # Keep for compatibility with ancient clients
        
        add_header Expires "0";
        # Another cache prevention method
        # Tells browser this content expired immediately
    }

    ########################################################################
    # LOCATION BLOCK 2: UPLOADS/STATIC FILES FROM BACKEND
    ########################################################################
    location /uploads {
        # Example use case: Backend stores uploaded files in /uploads directory
        # User uploads profile picture → saved to /uploads/profile-pics/user123.jpg
        # To view it: http://yoursite.com/uploads/profile-pics/user123.jpg
        
        proxy_pass http://backend_api;
        
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        
        expires 1d;
        # Explanation: Cache these files in browser for 1 day
        # Why: Images don't change often, caching saves bandwidth
        # User downloads profile pic once, uses cached version for 24 hours
        
        add_header Cache-Control "public, immutable";
        # "public" = can be cached by browser and CDN
        # "immutable" = file will never change (good for files with unique names)
    }

    ########################################################################
    # LOCATION BLOCK 3: NEXT.JS STATIC FILES
    # These are JavaScript/CSS files Next.js generates
    ########################################################################
    location /_next/static {
        # Explanation: Next.js puts all static assets in /_next/static
        # Example files:
        # /_next/static/chunks/main-abc123.js (JavaScript bundle)
        # /_next/static/css/styles-def456.css (CSS styles)
        #
        # The "abc123" hash changes when file changes
        # So we can cache aggressively - old files never get re-requested
        
        proxy_pass http://frontend_app;
        
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        
        expires 365d;
        # Explanation: Cache for 1 YEAR!
        # Why so long: Files have content hash in name
        # If file changes, filename changes, so cache is automatically invalidated
        # Example: main-abc123.js → main-xyz789.js (new deployment)
        
        add_header Cache-Control "public, immutable";
        # These files will NEVER change, so browser can cache forever
        
        add_header Access-Control-Allow-Origin *;
        # Explanation: Allow any domain to load these assets
        # Why: If you use a CDN or access site from different subdomain
        # Without this, browser blocks loading due to CORS policy
    }

    ########################################################################
    # LOCATION BLOCK 4: STATIC PUBLIC FILES
    # Files from Next.js public folder: favicon, robots.txt, etc.
    ########################################################################
    location ~ ^/(favicon\.ico|robots\.txt|sitemap\.xml) {
        # Explanation: The "~" means regex matching
        # ^ = start of URL
        # (favicon\.ico|robots\.txt|sitemap\.xml) = match any of these files
        # \. = literal dot (escaped)
        #
        # These are common files browsers/crawlers look for:
        # favicon.ico - website icon shown in browser tab
        # robots.txt - tells search engines which pages to index
        # sitemap.xml - helps search engines discover all your pages
        
        proxy_pass http://frontend_app;
        
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        
        expires 7d;
        # Cache for 7 days - these files rarely change
        # Not as aggressive as /_next/static since these don't have content hashes
        
        add_header Cache-Control "public";
        # Allow public caching
    }

    ########################################################################
    # LOCATION BLOCK 5: FRONTEND APPLICATION (CATCH-ALL)
    # Any request not matched above goes to Next.js
    ########################################################################
    location / {
        # Explanation: This matches EVERYTHING
        # Examples of what hits this block:
        # / (home page)
        # /login (login page)
        # /dashboard (dashboard page)
        # /users/123 (user profile page)
        # /anything-not-matched-above
        #
        # IMPORTANT: This must be the LAST location block
        # Nginx tries to match locations in order, this is the fallback
        
        proxy_pass http://frontend_app;
        
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        # WebSocket support for Next.js development hot reload
        # In production, also useful if you add real-time features
        
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
        
        add_header Cache-Control "no-cache, must-revalidate";
        # Explanation: Don't cache HTML pages
        # Why: Pages often contain dynamic content (user-specific data)
        # JavaScript and CSS are cached (via /_next/static), but not HTML
    }

    ########################################################################
    # LOCATION BLOCK 6: HEALTH CHECK ENDPOINT
    ########################################################################
    location /health {
        # Explanation: Simple endpoint that returns "OK"
        # Used by:
        # - Docker healthcheck (is container alive?)
        # - Load balancers (is server healthy?)
        # - Monitoring tools (is site up?)
        # - CI/CD pipelines (did deployment succeed?)
        
        access_log off;
        # Don't log health checks - they happen every 30 seconds
        # Would fill up logs with noise
        
        return 200 "OK\n";
        # Return HTTP 200 status with body "OK"
        # Simple and fast - no need to check backend
        
        add_header Content-Type text/plain;
        # Tell browser this is plain text, not HTML
    }

    ########################################################################
    # ERROR PAGES - Friendly error messages
    ########################################################################
    error_page 404 /404.html;
    # If page not found, show /404.html
    # You can create custom 404 page for better UX
    
    error_page 500 502 503 504 /50x.html;
    # Server error pages:
    # 500 = Internal Server Error (bug in backend code)
    # 502 = Bad Gateway (backend down or not responding)
    # 503 = Service Unavailable (backend overloaded)
    # 504 = Gateway Timeout (backend took too long to respond)
    
    location = /50x.html {
        root /usr/share/nginx/html;
        # Serve error page from Nginx's default HTML directory
        # This works even if backend is completely down
    }
}

############################################################################
# HTTPS CONFIGURATION (PRODUCTION)
#
# When you're ready for production with SSL/TLS:
# 1. Get SSL certificate (Let's Encrypt is free: https://letsencrypt.org)
# 2. Uncomment the server block below
# 3. Replace "example.com" with your actual domain
# 4. Update certificate paths
# 5. Copy all location blocks from HTTP server above
############################################################################
# server {
#     listen 443 ssl http2;
#     listen [::]:443 ssl http2;
#     
#     server_name example.com www.example.com;
#     
#     ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;
#     ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;
#     
#     ssl_protocols TLSv1.2 TLSv1.3;
#     ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256';
#     ssl_prefer_server_ciphers off;
#     
#     ssl_session_cache shared:SSL:10m;
#     ssl_session_timeout 10m;
#     
#     add_header Strict-Transport-Security "max-age=31536000" always;
#     
#     # Copy all location blocks from above here
# }

############################################################################
# HTTP TO HTTPS REDIRECT (PRODUCTION)
# Force all traffic to use HTTPS for security
############################################################################
# server {
#     listen 80;
#     listen [::]:80;
#     server_name example.com www.example.com;
#     
#     return 301 https://$server_name$request_uri;
# }
